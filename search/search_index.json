{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"\ud83d\udc15 Botzo","text":"<p>A legged robot platform designed to learn by building it!</p> <p> </p> <p></p> <p>Botzo is a legged robot platform which is aimed to help students and enthusiasts in robotics to simulate, build and program a robot. The project aim is to have a robot that it's cost should be targeted to be under the 500 euros mark.</p> <p>Furthermore, due to the nature of a quadruped robot, this platform should excel at the following:</p> <ul> <li>Navigate complex terrains</li> <li>Collect data and samples</li> <li>Interact with its environment</li> </ul>"},{"location":"#project-current-state","title":"Project Current State","text":"<p>This project is still in active development and currently in its early stages.</p> <p>So far, the platform has gone through component selection, CAD design and assembly, and building the inverse kinematics model. It's now in the simulation phase, where the goal is to use reinforcement learning to \"teach\" Botzo how to walk on its own.</p>"},{"location":"#why-botzo","title":"Why Botzo?","text":"<p>Botzo is a legged robot platform designed not just to function, but to teach. It was created with the goal of helping people learn about robotics by building, experimenting, and exploring key concepts along the way \u2014 from hardware design and assembly to control systems, simulation, and machine learning.</p> <p>Unlike many robotics kits that act as black boxes, Botzo is open and modular. Every part of it \u2014 mechanical, electrical, and software \u2014 is intended to be a learning opportunity. Whether you're diving into inverse kinematics or training locomotion with reinforcement learning, Botzo encourages curiosity and hands-on experimentation.</p> <p>If you're interested in robotics, simulation, or intelligent locomotion, Botzo isn't just a project \u2014 it's a platform for learning.</p> <p>BOTZO GITHUB REPO</p>"},{"location":"build/assembly/","title":"Guide","text":"<p>Info</p> <p>To be done!</p> <p></p>"},{"location":"build/hardware/","title":"Hardware","text":""},{"location":"build/hardware/#overview","title":"Overview","text":"<p>Botzo hardware components are aimed at being affordable but still of decent quality. The components can be summarized by the following 4 types:</p> <ul> <li>Processing Unit: Raspberry Pi 4 (future: Jetson Nano).</li> <li>Actuators: Optimizing torque for robust movement (25kg servos x3 per leg).</li> <li>Power Supply: Batteries capable of delivering ~30 minutes of runtime under typical conditions.</li> <li>Sensors: Integrating components for environmental awareness. Botzo top is universal base for attaching fourther components, such as webcam and LiDAR.</li> </ul> <p>For a deeper dive into this phase, check out our Canva Board Proposal.</p> Full Circuite Schematic highlighting the connections between components. Full Circuite Schematic highlighting the connections between components."},{"location":"build/hardware/#bill-of-materials","title":"Bill Of Materials","text":""},{"location":"build/hardware/#electronics","title":"Electronics","text":"Component Link Price (Single) Component Total Description Quantity Arduino Mega Amazon 25.99\u20ac 25.99\u20ac Control over servos and IMU x1 Raspberry Pi - - - Brain x1 Raspberry Pi camera module V2 8MP Amazon 13.79\u20ac 13.79\u20ac Camera module for Raspberry x1 Buck converter 5V-5A out Amazon 11.99\u20ac 11.99\u20ac Buck converter 5V-5A (25W) for Rpi x1 Buck converter 5-40V 12A out Amazon 35.99\u20ac 35.99\u20ac Buck converters for servos x5 Servo DS3225 25kg - - - Actuators for legs x12 MPU-6050 - - - Balancing sensor x1 LiPo batteries RC Amazon 45.99\u20ac 91.98\u20ac Power in series x2 Oled Display Amazon 9.99\u20ac 9.99\u20ac Display informations x1 PS3 controller Amazon 17.99\u20ac 17.99\u20ac PS3 controller to move robot x1"},{"location":"build/hardware/#fastners-materials","title":"Fastners &amp; Materials","text":"Component Link Price (Single) Component Total Description Quantity 8x3x4 mm bearings Amazon 7.09\u20ac 14.18\u20ac Bearings for moving parts x20 10x5x4 mm bearings Amazon 7.09\u20ac 7.09\u20ac For shoulder stronger axes x4 Dean T Connectors Amazon 9.99\u20ac 9.99\u20ac Connection of the circuit x1 Cables 14 AWG Amazon 25.5\u20ac 25.5\u20ac Cables high current x1 Cables 10 AWG Amazon 16.99\u20ac 16.99\u20ac Cables high current x1 TPU filament Bambu 44.73\u20ac 44.73\u20ac TPU for foot x1 PETG filament Amazon - - TPU for foot x1 Set of M3, M2.5 and M2 screws - - - - - Set of inserts for M3, M2.5 and M2 screws - - - - - <p>Total: 256.39\u20ac</p> <p>Price can vary depending on what you already have, but the goal is to stay under 500\u20ac</p>"},{"location":"build/cad/cad-model/","title":"CAD Model","text":"<p>Botzo has been primarily designed using Fusion 360 CAD software. To support this, we provide a <code>.f3z</code> file that can be imported directly into Fusion 360. Additionally, <code>.step</code> files are available for users who prefer other CAD software.</p> <p>Since Botzo is designed for 3D printing, all printable components are provided as STL files. These are ready to be loaded into a slicer and printed using an FDM printer.</p> <p>All CAD files are available in the Botzo repository: \ud83d\udcc1 View on GitHub</p>"},{"location":"build/cad/cad-model/#about-the-design","title":"About the Design","text":""},{"location":"build/cad/cad-model/#the-leg","title":"The Leg","text":"<p>The leg design was inspired by the project Chop by Miguel Ayusto Parrilla. By concentrating most of the weight in the shoulder, this design reduces leg inertia, improving walking stability.</p> <p></p>"},{"location":"build/cad/cad-model/#the-body","title":"The Body","text":"<p>The body is designed to house all internal components and cable routing while leaving space on the dorsal side for mounting additional modules like a LiDAR or webcams\u2014supporting future capabilities like mapping and vision.</p> <p></p> <p>BOTZO CAD REPO</p>"},{"location":"build/cad/urdf/","title":"Robot URDF","text":"<p>OWR URDF</p>"},{"location":"build/cad/urdf/#what-is-a-urdf-and-why-we-need-it","title":"What is a URDF and why we need it?","text":"<p>A URDF is a file used in robotics to import the robot in a simulation. It uses the STL/CAD files as a base. Assemble them with rigid or rotatory joins, and save positions of each bone and pivot in the joints. To sum up, it is file that describe your robot in deep details and precision.</p>"},{"location":"build/cad/urdf/#how-to-create-a-urdf-for-botzo","title":"How to create a URDF for Botzo","text":"<p>From the CAD files, we created a URDF file for Botzo using Fusion 360 and fusion2urdf. A repo that give us a package for exporting URDF from a Fusion 360 packages.</p> <p>Visit directly the repos if you don't understand something. This is a resume of what they do:</p> <ul> <li> <p>Webgraphviz (for debugging purposes)</p> </li> <li> <p>fusion2urdf (for exporting URDF from Fusion 360 file assembled with joints)</p> </li> </ul>"},{"location":"build/cad/urdf/#result-and-prcedure","title":"Result and prcedure","text":"<p>You will use BOTZO_F360_JOINS.f3d file to build your urdf, or just use ours here.</p>"},{"location":"build/cad/urdf/#prepare-stl","title":"Prepare STL","text":"<p>As stated in the Fusion2PyBullet repo and fusion2urdf, we must prepare our STL file properly with strict rules:</p> <ol> <li>All bodies/peaces/future links must be components.</li> <li>Add physical materials</li> <li>Add joint to connect all components. In fusion you can select various type of joint (static, rotational, etc...) and also the pivot point.</li> <li>Call one component as <code>base_link</code></li> <li>Remove links of components (if the are right click on it and press Break Link)</li> <li> <p>Check STL joint-link structure using Webgraphviz. Here how:</p> <ul> <li>Download Joint2Graphviz repo as a ZIP.</li> <li>Extract the ZIP in a known directory.</li> <li> <p>Open terminal:</p> <pre><code>cd &lt;path to Joint2Graphviz&gt;\n\nCopy-Item \".\\Joint2Graphviz-master\\\" -Destination \"${env:APPDATA\\Autodesk\\Autodesk Fusion 360\\API\\Scripts\\\" -Recurse\n</code></pre> <p>For me was: <pre><code> cd C:\\Users\\orlan\\OneDrive\\Desktop\\side_projects\\Joint2Graphviz-master\n\n Copy-Item \"..\\Joint2Graphviz-master\\\" -Destination \"..\\..\\..\\..\\AppData\\Roaming\\Autodesk\\Autodesk Fusion 360\\API\\Scripts\\\" -Recurse\n</code></pre>     - Now the script to create a <code>.txt</code> file for your link graph is added to fusion     - Open fusion     - Open the file of the robot     - Go to utility &gt; Addins     - Under <code>My Script</code> you should see <code>Joint2Graphviz</code>     - Press it. It will create a <code>graph.txt</code></p> </li> <li> <p>Copy and pase the text content to Webgraphviz and check your robot tf structure to be valid.</p> </li> </ul> </li> </ol> <p>(for more infors check Joint2Graphviz readme)</p> <p>Warning</p> <ol> <li>We discovered that URDF does NOT suport close loop. Our leg design is one big close loop. You can check <code>wrong_graph</code> folder to see a graph with a close loop... The URDF won't work if there is a close loop</li> </ol>"},{"location":"build/cad/urdf/#export-urdf","title":"Export URDF","text":"<ol> <li>Download fusion2urdf</li> <li>Extract the ZIP in a known directory.</li> <li> <p>Open terminal:</p> <pre><code>cd &lt;path to Fusion2PyBullet&gt;\n\nCopy-Item \".\\URDF_Exporter\\\" -Destination \"${env:APPDATA}\\Autodesk\\Autodesk Fusion 360\\API\\Scripts\\\" -Recurse\n</code></pre> <p>For me was: <pre><code>    PS C:\\Users\\orlan\\OneDrive\\Desktop\\side_projects\\Fusion2PyBullet-master&gt; Copy-Item \".\\Bullet_URDF_Exporter\\\" -Destination \"..\\..\\..\\..\\AppData\\Roaming\\Autodesk\\Autodesk Fusion 360\\API\\Scripts\\\" -Recurse\n</code></pre> 4. Open fusion &gt; utils &gt; addins &gt; my scripts &gt; Bullet_URDF_Exporter</p> </li> </ol> <p>(for more infors check fusion2urdf readme or Fusion2PyBullet readme)</p> <ol> <li> <p>You will recive a folder with all the scrips and files to simulate your robot in ROS/Gazebo or PyBullet. To simply extract the URDF from XACRO use this comand:</p> <pre><code>ros2 run xacro xacro &lt;your_file&gt;.xacro &gt; &lt;your_file&gt;.urdf\n</code></pre> </li> <li> <p>OWR URDF</p> </li> </ol> <p>BOTZO URDF REPO</p>"},{"location":"build/software/firmware/","title":"Firmware","text":"<p>Info</p> <p>To be done!</p>"},{"location":"build/software/ros/","title":"ROS","text":"<p>Info</p> <p>To be done!</p>"},{"location":"changelog/","title":"Changelog","text":"<p>Tip</p> <p>This can serve a place where we can write for example every month what has been accomplished, or if some important step has been made. As a possible way of doing this can be the following. Furthermore, we can use automated tools like git-cliff to generate good looking changelogs based on the commit messages.</p>"},{"location":"changelog/#06082025-initial-draft","title":"06/08/2025 - Initial Draft","text":"<p>This marks the beginning of having a proper documentation for our project Botzo. We have added support to generate documentation using material mkdocs...</p>"},{"location":"contribute/faq/","title":"FAQ","text":"<p>Info</p> <p>To be done!</p>"},{"location":"contribute/how-to/","title":"How to Contribute","text":"<p>Info</p> <p>To be done!</p>"},{"location":"getting-started/installation/","title":"Installation & Setup","text":"<p>Info</p> <p>To be done!</p>"},{"location":"learn/create-urdf/","title":"Generating Botzo URDF","text":"<p>Documentation on how to build our URDF from STL file</p> <p>A URDF is a file used i robotics to import the robot in a simulation. It uses the STL/CAD files as a base. Assemble them with rigid or rotatory joins, and save positions of each bone and pivot in the joints. To sum up, it is file that describe your robot in deep details and precision.</p> <p>Download our URDF here</p>"},{"location":"learn/create-urdf/#resources","title":"Resources","text":"<p>Visit directly the repos if you don't understand something. This is a resume of what they do:</p> <ul> <li>Webgraphviz</li> <li>Joint2Graphviz repo zip</li> <li>Fusion2PyBullet repo zip</li> <li>fusion2urdf &lt;-- deprecated</li> </ul>"},{"location":"learn/create-urdf/#prepare-stl","title":"Prepare STL","text":"<p>As stated in the Fusion2PyBullet repo, we must prepare our STL file properly.</p> <ol> <li>All bodies/peaces/future links must be components.</li> <li>Add physical materials</li> <li>Add joint to connect all components. In fusion you can select various type of joint (static, rotational, etc...) and also the pivot point.</li> <li>Call one componet as <code>base_link</code></li> <li>Remove links of comonents (if the are right clik on it and press Break Link)    Result: https://github.com/IERoboticsAILab/botzo/blob/main/media_assests/fusion_joints_one_leg.mp4    </li> <li> <p>Check STL joint-link structure using Webgraphviz. Here how:</p> </li> <li> <p>Download Joint2Graphviz repo as a ZIP.</p> </li> <li>Extract the ZIP in a known directory.</li> <li> <p>Open terminal:</p> <pre><code>cd &lt;path to Joint2Graphviz&gt;\n\nCopy-Item \".\\Joint2Graphviz-master\\\" -Destination \"${env:APPDATA\\Autodesk\\Autodesk Fusion 360\\API\\Scripts\\\" -Recurse\n</code></pre> <p>For me was:</p> <pre><code> cd C:\\Users\\orlan\\OneDrive\\Desktop\\side_projects\\Joint2Graphviz-master\n\n Copy-Item \"..\\Joint2Graphviz-master\\\" -Destination \"..\\..\\..\\..\\AppData\\Roaming\\Autodesk\\Autodesk Fusion 360\\API\\Scripts\\\" -Recurse\n</code></pre> </li> <li> <p>Now the script to create a <code>.txt</code> file for your link graph is added to fusion</p> </li> <li>Open fusion</li> <li>Open the file of the robot</li> <li>Go to utility &gt; Addins</li> <li>Under <code>My Script</code> you should see <code>Joint2Graphviz</code></li> <li>Press it. It will create a <code>graph.txt</code></li> <li>Copy and pase the text content to Webgraphviz and check your robot tf structure to be valid.</li> </ol> <p>(for more infors check Joint2Graphviz readme)</p> <p>Warning</p> <ol> <li>We discovered that URDF does NOT suport close loop. Our leg design is one big close loop. You can check <code>wrong_graph</code> folder to see a graph with a close loop... The URDF won't work if there is a close loop</li> </ol>"},{"location":"learn/create-urdf/#export-urdf","title":"Export URDF","text":"<ol> <li>Download Fusion2PyBullet as a ZIP</li> <li>Extract the ZIP in a known directory.</li> <li>Open terminal:</li> </ol> <pre><code>cd &lt;path to Fusion2PyBullet&gt;\n\nCopy-Item \".\\URDF_Exporter\\\" -Destination \"${env:APPDATA}\\Autodesk\\Autodesk Fusion 360\\API\\Scripts\\\" -Recurse\n</code></pre> <p>For me was:</p> <pre><code>    PS C:\\Users\\orlan\\OneDrive\\Desktop\\side_projects\\Fusion2PyBullet-master&gt; Copy-Item \".\\Bullet_URDF_Exporter\\\" -Destination \"..\\..\\..\\..\\AppData\\Roaming\\Autodesk\\Autodesk Fusion 360\\API\\Scripts\\\" -Recurse\n</code></pre> <ol> <li>Open fusion &gt; utils &gt; addins &gt; my scripts &gt; Bullet_URDF_Exporter</li> <li>My URDF here</li> </ol> <p>(for more infors check fusion2urdf readme or Fusion2PyBullet readme)</p> <p>BOTZO URDF REPO</p>"},{"location":"learn/gait-plan/","title":"Gait Planning","text":"<p>Info</p> <p>To be done!</p>"},{"location":"learn/inverse-kinematics/","title":"Inverse Kinematics","text":"<p>Inverse Kinematics (IK) is a mathematical approach used in robotics to determine the necessary joint angles to position an end-effector (like a robotic arm or leg) at a specific point in space. This is particularly useful for robots with multiple degrees of freedom (DoF), such as our botzo v2s, which has 3 DoF per leg.</p> <p>Inverse Kinematics is used in robots with legs or arms. It is a series of matrix moltiplications and trigonometry formulas (sin, cos,atan2 law of cosin, pitagora, etc...), in order too find the angles each motor in the leg need to have to reach a point in space (x,y,z). Our dog have 3 Degrees of freedom (3DoF), meaning 3 motors per leg.</p> <p>On the other side forward kinematics calculate where the end-effector/the foot end up based on given/known angles of each motor.</p> <p>Both uses known constants such as lenght of each \"bone\". For Inverse Kinematic also the target point is a known variable, and it allow us to find the angle configuration we need to reach that point in space.</p> <p></p> <p></p> <p>Note</p> <p>In <code>coordinates_to_servos.ipynb</code> we have combined the use of our IK with the transformation from degrees to PWM explained in calibrate servos repo</p>"},{"location":"learn/inverse-kinematics/#3-dof-ik-of-1-leg","title":"3 DoF IK Of 1 leg","text":""},{"location":"learn/inverse-kinematics/#solver","title":"Solver","text":"<p>Note:</p> <pre><code>coxa = A = 3.1 cm\nfemur = E = 9.5 cm\nreal_femur = E' = 9.1 cm\ntibia = F = 9.8 cm\n\u03b8(coxa) = \u03c8\n\u03b8(knee) = \u03a6\n\u03b8(shoulder) = \u03b8\ndist_focuspoint_servo_femurtibia = 2.8 cm\nX, Y, Z = given target point\n</code></pre> <p></p> <ol> <li>Distance Calculation</li> </ol> <pre><code>D = \\sqrt{Z^2 + Y^2 - \\text{A}^2}\n</code></pre> <ol> <li>G Calculation</li> </ol> <pre><code>G = \\sqrt{D^2 + X^2}\n</code></pre> <ol> <li>Knee Angle</li> </ol> <pre><code>\\text{\u03a6} = \\arccos\\left(\\frac{G^2 - \\text{E}^2 - \\text{F}^2}{-2 \\cdot \\text{E} \\cdot \\text{F}}\\right)\n</code></pre> <ol> <li>Shoulder Angle</li> </ol> <pre><code>\\theta_{\\text{shoulder}} = \\arctan2(X, D) + \\arcsin\\left(\\frac{\\text{F} \\cdot \\sin(\\text{\u03a6})}{G}\\right)\n</code></pre> <ol> <li>Coxa Angle</li> </ol> <pre><code>\\text{\u03c8} = \\arctan2(Y, Z) + \\arctan2(D, \\text{A})\n</code></pre>"},{"location":"learn/inverse-kinematics/#translator","title":"Translator","text":"<p>Here we will translate the founded angles with the translator in the actual angles we will pass to the robot servos</p> <p></p> <ol> <li>Adjustment</li> </ol> <pre><code>\\text{adjustment} = \\arccos\\left(\\frac{\\text{real\\_femur}^2 + \\text{femur}^2 - \\text{dist\\_focuspoint\\_servo\\_femurtibia}^2}{2 \\cdot \\text{real\\_femur} \\cdot \\text{femur}}\\right)\n</code></pre> <ol> <li>Femur Angle</li> </ol> <pre><code>\\theta_{\\text{femur}} = \\frac{\\pi}{2} - (\\theta_{\\text{shoulder}} + \\text{adjustment})\n</code></pre> <ol> <li>Tibia Angle</li> </ol> <pre><code>\\theta_{\\text{tibia}} = \\pi - \\theta_{\\text{knee}} + \\text{adjustment} + \\theta_{\\text{femur}}\n</code></pre>"},{"location":"learn/inverse-kinematics/#resources","title":"Resources","text":"<p>Spot-Micro</p> <ul> <li> <p>Spot-Micro GitHub</p> </li> <li> <p>Spot-Micro IK solver video</p> </li> </ul> <p>OpenQuadruped/spot_mini_mini</p>"},{"location":"learn/inverse-kinematics/#rotation-matrices","title":"Rotation Matrices","text":"<p>Note</p> <p>Rotation matrices repo: here</p> <p>Rotation matrices docs: here</p>"},{"location":"learn/inverse-kinematics/#ik-full-body","title":"IK full body","text":"<p>Use <code>IK_solver4Lgs.ipynb</code>. It is a way to manualy retrive angles for each leg to make robot step and walking for the first time.</p> <ol> <li>First the code loads known variables, such as the coefficents retrived from the calibration of each servo (find more here).</li> </ol> <p>and robot dimentions.</p> <ol> <li> <p>We define some usefull function for later (such as translate read to degrees)</p> </li> <li> <p>We craete a IK solver for each leg. The only thing that changes is the adjustemts need for each leg servo angle. Because some servos has diffrent orientation therfor diffrent zero.</p> </li> <li> <p>Then we manualy define points in the 3D space (x,y,z) inside an array. This points will then later be passed one by one to the IK solvers adn we will return PWM signals for the corrisponding angle that each servo need to have to reach that point.</p> </li> <li>Each leg has his own IK solver, given the fact that the motors are oriented in diffrent ways.</li> <li>Differences from Front to Back: Just in the shoulder angle, infact the servo is oriented on the opposite side. So we just do <code>180\u00b0 - angle_in_right</code></li> </ol> <p>FR</p> <pre><code>coxa_angle = deg2rad(180) - (np.arctan2(y,z) + np.arctan2(D,coxa))\n</code></pre> <p>BR <pre><code>coxa_angle = (np.arctan2(y,z) + np.arctan2(D,coxa))\n</code></pre></p> <ul> <li> <p>Differences from Left to Right:</p> <ol> <li>First we have to flip both angles in knee and tibia of about 180\u00b0.</li> </ol> <p>FR</p> <pre><code>femur_angle = deg2rad(90) - (shoulder_angle + adjustment)\ntibia_angle = np.pi - knee_angle + femur_angle + adjustment\n</code></pre> <p>FL</p> <pre><code>femur_angle = (deg2rad(90) - (shoulder_angle + adjustment))\ntibia_angle = deg2rad(180) - (np.pi - knee_angle + femur_angle + adjustment)\nfemur_angle = deg2rad(180) - femur_angle\n</code></pre> <ol> <li>We have to change the position of the shoulder. The math think that the shoulder is at the right of the leg, but in the right leg, the shoulder servo is at the left to respect to the leg (indide the robot).</li> </ol> <p>We want to achive this:</p> <p></p> <p>But the math make the robot beleve it is in this configuration (where the leg is duplicated, not mirrored):</p> <p></p> <p>So the result of IK solver is something like this (not precise, and mooving on a curve rather than a line):</p> <p></p> <p>After the flip we end up in the desire configuration (we basically move the shoulder inside the robot. In other words we flip the output angle of the shoulder based on the vertical line):</p> <p></p> <p>FR</p> <pre><code>coxa_angle = deg2rad(180) - (np.arctan2(y,z) + np.arctan2(D,coxa))\n</code></pre> <p>FL</p> <pre><code>coxa_angle = (deg2rad(180) - (np.arctan2(y,z) + np.arctan2(D,coxa))) - (2 * ((deg2rad(180) - (np.arctan2(y,z) + np.arctan2(D,coxa)))-deg2rad(90)))\n</code></pre> </li> <li> <p>We parse the result in a way the we can just copy and paste it in the <code>test_4legs.ino.ino</code> arduino code. The arduino code connect to each servo and move them coordinately. So we where able to manualy simulate a Walking Gate. For a more general and sophisticated gate look here</p> </li> </ul> <p> </p> <p>BOTZO IK REPO</p>"},{"location":"learn/reinforcement-learning/","title":"Reinforcement Learning","text":"<p>Info</p> <p>To be done!</p>"},{"location":"learn/rotation-matrices/","title":"Rotation Matrices","text":"<p>Info</p> <p>To be done!</p>"},{"location":"learn/servo-calibration/","title":"Servo Calibration","text":"<p>Note</p> <p>This guide can be quite improved.</p> <p>Servos work by using PWM (Pulse Width Modulation) signals, where different pulse widths correspond to specific angles. Typically, this ranges between 500 \u00b5s and 2000 \u00b5s. However, due to manufacturing tolerances\u2014especially in more affordable servos\u2014there can be significant variation in how each servo responds to the same PWM signal.</p> <p>To improve accuracy, each servo can be calibrated to determine its specific PWM response curve. This only requires some simple math and a bit of setup.</p>"},{"location":"learn/servo-calibration/#result","title":"Result","text":"Before Calibration After Calibration <p>With calibration, servo motion becomes noticeably more accurate and consistent.</p>"},{"location":"learn/servo-calibration/#repo-content","title":"Repo Content","text":"<ol> <li> <p><code>Calibration_Procedure.ipynb</code>: A Google Colab notebook that fits a least-squares    regression to convert angles to PWM values specific to each servo.</p> </li> <li> <p><code>calibarte_servos.ino</code>: Arduino code to help identify real PWM values using the Calibration Tool.</p> </li> <li> <p><code>save_coefficients/</code>: Folder containing <code>.csv</code> and <code>.xlsx</code> files used to store    calibration data for each leg and servo.</p> </li> </ol>"},{"location":"learn/servo-calibration/#background-and-motivation","title":"Background and Motivation","text":"<p>Servos are controlled by PWM signals to reach a given angle. However, each servo has unique mechanical and electrical characteristics that lead to deviations between the desired angle and the actual angle achieved.</p> <p>This calibration process helps:</p> <ol> <li>Measure how each servo responds to standard angles.</li> <li>Fit a custom curve (linear or quadratic) for more accurate angle-to-PWM mapping.</li> </ol> <p>The theoretical formula from datasheets is often:</p> <ul> <li>PWM = 7.4 \u00d7 desired_angle + 500</li> </ul> <p>So for example:</p> <ul> <li><code>[0, 45, 90, 135, 180]</code> degrees \u2192 <code>[500, 833, 1166, 1500, 1832]</code> PWM values</li> </ul> <p>However, these are idealized values\u2014calibration helps find the real-world equivalent.</p>"},{"location":"learn/servo-calibration/#process-of-calibration","title":"Process of Calibration","text":"<ol> <li> <p>Compute ideal PWM values    Use Cell 1 of the notebook to calculate PWM values for known angles using the    datasheet formula.</p> </li> <li> <p>Align servo using Arduino code    Upload the Arduino sketch    and use the serial monitor to manually tune PWM values until the servo aligns with    target angles (0\u00b0, 45\u00b0, 90\u00b0, 135\u00b0, 180\u00b0).</p> </li> <li> <p>Record the actual PWM values    Example values from the Front Right leg:</p> </li> </ol> <pre><code>real_pwm_SFR = np.array([564, 890, 1219, 1564, 1897])\nreal_pwm_FFR = np.array([606, 930, 1265, 1606, 1930])\nreal_pwm_TFR = np.array([555, 895, 1230, 1580, 1910])\n</code></pre> <ol> <li> <p>Fit a regression curve    Use least-squares regression to generate coefficients for the curve that maps    desired degrees to PWM for each servo.</p> </li> <li> <p>Test and verify accuracy    Use the new function to convert angles into PWM and verify improved motion accuracy.</p> </li> </ol>"},{"location":"learn/servo-calibration/#cell-1-setup-and-pwm-conversion","title":"Cell 1 \u2013 Setup and PWM Conversion","text":"<pre><code># Libraries\nimport numpy as np\n\n# Convert desired angles (degrees) to PWM using datasheet formula\ndef deg2PWM(desire_deg_angles):\n    output = []\n    for angle in desire_deg_angles:\n        pulse = round((7.4074 * angle) + 500, 0)\n        output.append(pulse)\n        print(f\"// {angle} degrees =&gt; {pulse} PWM\")\n    return output\n\n# Example usage\ndesire_angles = [0, 45, 90, 135, 180, 270]\ndesired_PWM = deg2PWM(desire_angles)\nprint(\"\\nDesired PWM values:\", desired_PWM)\n\nprint(\"\\nPlease run these PWM signals and record the actual angles reached.\")\n</code></pre>"},{"location":"learn/servo-calibration/#arduino-procedure","title":"Arduino Procedure","text":"<ol> <li>Upload the Arduino sketch.</li> <li>Open the serial monitor and set the PWM to 500.</li> <li>Attach the servo arm using the calibration tools aligned as closely as possible to 0\u00b0.</li> <li>Adjust the PWM value until the arm aligns perfectly with 0\u00b0.</li> <li>Record the PWM, and repeat for 45\u00b0, 90\u00b0, 135\u00b0, and 180\u00b0.</li> </ol>"},{"location":"learn/servo-calibration/#cell-2-save-real-pwm-values","title":"Cell 2 \u2013 Save Real PWM Values","text":"<pre><code>real_pwm_SFR = np.array([564, 890, 1219, 1564, 1897])\n</code></pre>"},{"location":"learn/servo-calibration/#cell-3-run-regression","title":"Cell 3 \u2013 Run Regression","text":"<pre><code>import matplotlib.pyplot as plt\n\n# Input: degrees and corresponding real PWM values\ndegrees = np.array([0, 45, 90, 135, 180])\nreal_pwm = real_pwm_SFR  # Replace with your servo data\n\n# Fit a quadratic regression curve\ncoefficients = np.polyfit(degrees, real_pwm, 2)\na, b, c = coefficients\n\nprint(f\"Quadratic coefficients: a = {a}, b = {b}, c = {c}\")\n\n# Plotting\nplt.scatter(degrees, real_pwm, color='blue', label='Measured data')\nx_vals = np.linspace(0, 180, 1000)\ny_vals = a * x_vals**2 + b * x_vals + c\nplt.plot(x_vals, y_vals, color='red', label=f'Fit: {a:.2f}x\u00b2 + {b:.2f}x + {c:.2f}')\nplt.xlabel('Degrees')\nplt.ylabel('PWM')\nplt.title('Servo Calibration Curve')\nplt.legend()\nplt.grid(True)\nplt.show()\n</code></pre>"},{"location":"learn/servo-calibration/#notes","title":"Notes","text":"<ul> <li>Calibrate each servo individually, as they may have different characteristics.</li> <li>Keep the servo horn attached after calibration\u2014removing it will require redoing the process.</li> <li>Store your coefficients securely for consistent motion across reboots or deployments.</li> </ul> <p>By following this process, you\u2019ll significantly improve servo positioning accuracy, making your robot\u2019s motion more reliable and repeatable.</p> <p>BOTZO SERVO CALIBRATION REPO</p>"},{"location":"simulation/setup/","title":"Botzo Simulation","text":"<p>To create a digital twin of our real robot we built a URDF file from the CAD model in Fusion 360 (for more details see here). A URDF file is a format used in robotics to describe the physical properties of a robot, including its geometry, links and meshes positions. It allows for simulation and visualization of the robot in simulation environments.</p> <p>The goal will be to create an exact twin of botzo in a digital space, allowing us to test algorithms, simulate movements, and visualize the robot's behavior without needing the physical hardware. This is particularly useful for testing and development purposes.</p> <p>Our final aim is to train and teach botzo to perform tasks using Reinforcement Learning in simulator engines such as Pybullet + Mujoco or IsaacLab. This will allow Botzo to learn how to stabilize his walking, climb stairs and even perform tricks like jumping or dancing, all in a safe and controlled environment before applying the learned behaviors to the physical robot. </p>"},{"location":"simulation/setup/#simulation-folder","title":"<code>simulation/</code> folder","text":"<p>Note</p> <p>We recommend to create a virtual environment to run the code in this folder, and install PyBullet and Numpy.</p> <ul> <li> <p><code>utils/</code>: Contains a script used by the simulations scripts to import our Inverse Kinematics algorithm, which is used to calculate the angles of the motors based on the desired position of the robot's feet. Using the exact same algorithm used in the real robot, we can ensure that the simulation behaves similarly to the physical robot. (find here)</p> </li> <li> <p>PyBullet scripts:</p> </li> <li><code>spawn_botzo.py</code>: Load URDF, basic script of PyBullet (find here)</li> <li><code>move_one_joint.py</code>: Just to showcase how we access and move joints in Pybullet. So in this script we move one joint of botzo (find here)</li> <li><code>debugger.py</code>: A script that allow us to move specific joints defined by the user. It is used to find the joint zeros, so we create a function that transform simulation joint to real joint position (find here)</li> <li><code>IK_one_leg.py</code>: A script to test and visualize the Inverse Kinematics algorithm for one leg of botzo in PyBullet. It allows us to see how the IK algorithm calculates the joint angles needed to position the leg's foot at a desired location in 3D space. (find here)</li> <li><code>digital_twin.py</code>: The main script to simulate the full botzo robot in PyBullet using the URDF file. It incorporates the Inverse Kinematics algorithm to control the robot's movements, allowing us to test and visualize how botzo would behave in a digital environment. (find here)</li> </ul> <p>BOTZO SIMULATION REPO</p>"}]}